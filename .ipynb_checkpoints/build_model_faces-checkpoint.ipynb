{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #install dependencies \n",
    "# ! pip install --upgrade pip\n",
    "# !pip install numpy --upgrade\n",
    "# ! pip install pandas --upgrade\n",
    "# ! pip install boto3 --upgrade\n",
    "# ! pip install requests --upgrade\n",
    "# ! pip install scikit-learn --upgrade\n",
    "# ! pip install tensorflow --upgrade\n",
    "# ! pip install keras --upgrade\n",
    "# ! pip install scikit-video --upgrade\n",
    "# ! pip install scikit-image --upgrade\n",
    "# !pip install sagemaker --upgrade\n",
    "# ! pip install opencv-python --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import cv2 as cv\n",
    "import os\n",
    "import time\n",
    "import random \n",
    "import json\n",
    "from joblib import dump, load\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, Activation\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import load_model\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "face_detector = MTCNN()\n",
    "#sensitive variables in config.py file that is on .gitignore\n",
    "from config import key_, secret_, s3_bucket, kaggle_cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video_from_s3_bucket(video_name, aws_key=key_, aws_secret=secret_, bucket=s3_bucket):\n",
    "    '''\n",
    "    ##Intended for use when not using Sagemaker##\n",
    "    takes a video name as input, and returns a downloaded video from s3 bucket in an array\n",
    "    '''\n",
    "    s3 = boto3.client('s3',\n",
    "                      aws_access_key_id=aws_key, \n",
    "                      aws_secret_access_key=aws_secret,\n",
    "                      region_name='us-east-2', #region is hardcoded - this is not a security risk to keep public\n",
    "                      config= boto3.session.Config(signature_version='s3v4')) #the sig version needs to be s3v4 or the url will error\n",
    "    video_url = s3.generate_presigned_url('get_object',\n",
    "                                        Params={\"Bucket\": bucket,\n",
    "                                               'Key': video_name},\n",
    "                                        ExpiresIn=6000)\n",
    "    return video_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_frame(video_link, skipped_frames=5):\n",
    "    '''\n",
    "    function that takes a link to a video, and returns the frame after 'skipped_frames' input variable\n",
    "    temporary function to prevent large amount of bucket queries -- combine with resize and detect image function later\n",
    "    '''\n",
    "    video = cv.VideoCapture(video_link)\n",
    "    frame_count = int(video.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    for skipped_frame in np.arange(0, (skipped_frames + 1)):\n",
    "        _ = video.grab()\n",
    "    _, frame = video.retrieve()\n",
    "    video.release()\n",
    "    return frame\n",
    "# look into improving this - 701 ms when loading from bucket, 50 ms when loading from file, 5 skipped frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_detect_face(frame, new_max_size=750, padding=(.1, 0.05, 0.05)):\n",
    "    '''\n",
    "    temporary function -- combine with grab frame later\n",
    "    -- want to reduce number of bucket queries--\n",
    "    inputs:\n",
    "    frame: a single frame or an image\n",
    "    new_max_size: the maximum size of the longer of the width/height the frame will be resized to prior\n",
    "    to looking for faces\n",
    "    padding: tuple of percentages; will be added to the size of the face to ensure the entire face is captured\n",
    "    -- the tuple is (top, bottom, horizontal)\n",
    "    the top param will move the top of the face by this param times the size of the face towards the top of the y axis\n",
    "    the bottom param will move the bottom of the face by this praram times the size of the face towards the bottom\n",
    "    the horizontal param will move the left and right edges of the face by this param towards the left and\n",
    "    right edges of the plane respectively\n",
    "    returns:\n",
    "    a list of arrays\n",
    "    each array is a cropped face with dimensions of 146 by 225 pixels\n",
    "    '''\n",
    "    #convert the frame to color\n",
    "    #unsure if this step is necessary, however cvtColor takes very little time (~200 Âµs )\n",
    "    img = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    original_height = frame.shape[0]\n",
    "    original_width = frame.shape[1]\n",
    "    #get original shape of frame\n",
    "    original_height, original_width = frame.shape[0], frame.shape[1]\n",
    "    #get aspect ratio -- want to maintain this\n",
    "    img_size_ratio = original_height / original_width\n",
    "    #if the height is greater than the width, make new height the new_max_size, and\n",
    "    #make new width the new height divided by the aspect ratio\n",
    "    if original_height > original_width:\n",
    "        new_height = new_max_size\n",
    "        new_width = new_height / img_size_ratio\n",
    "    #otherwise, make the new width equal to the new max size, and \n",
    "    #the new height the new width times the aspect ratio\n",
    "    else:\n",
    "        new_width = new_max_size\n",
    "        new_height = new_width * img_size_ratio\n",
    "    #new dimensions -- the aspect ratio will not match exactly due to rounding, but will be close\n",
    "    new_dim = (int(new_width), int(new_height))\n",
    "    #resize the image while maintaining the aspect ratio, and changing the maximum edge length to new_max_size\n",
    "    resized_image = cv.resize(img, new_dim, interpolation = cv.INTER_AREA)\n",
    "    face_dictionaries = face_detector.detect_faces(resized_image)\n",
    "    faces = []\n",
    "    for face in range(len(face_dictionaries)):\n",
    "        if face_dictionaries[face]['confidence'] > 0.9:\n",
    "            box = face_dictionaries[face]['box']\n",
    "            start_x = box[0] - (padding[2] * box[2])\n",
    "            end_x = box[0] + ((1 + padding[2]) * box[2])\n",
    "            start_y = box[1] - (padding[1] * box[3])\n",
    "            end_y = box[1] + ((1 + padding[0]) * box[3])\n",
    "            if start_x < 0:\n",
    "                start_x = 0\n",
    "            if start_y < 0:\n",
    "                start_y = 0\n",
    "            #keep consistant - do additional research on this\n",
    "            face_ratio = 1.54 # will keep horizontal size the same (can experiment with adjusting the horizontal axis later)\n",
    "            #calculate the number of pixels the face is on the horizontal axis\n",
    "            x_size = end_x - start_x\n",
    "            #calculate the number of pixels the face is on the vertical axis\n",
    "            y_size = end_y - start_y\n",
    "            #get what y_size needs to be\n",
    "            y_size_with_ratio = x_size * face_ratio\n",
    "            #how much the y_size needs to be adjusted\n",
    "            y_size_change = y_size_with_ratio - y_size\n",
    "            start_y_ = start_y - y_size_change\n",
    "            end_y_ = end_y + y_size_change\n",
    "            if start_y_ < 0:\n",
    "                y_adjust = 0 - start_y_\n",
    "                end_y_ = min((end_y_ + y_adjust), resized_image.shape[0])\n",
    "                start_y_ = 0\n",
    "            elif end_y_ > resized_image.shape[0]:\n",
    "                y_adjust = end_y_ - resized_image.shape[0]\n",
    "                start_y_ = max(0, (start_y_ - y_adjust))\n",
    "                end_y_ = resized_image.shape[0]\n",
    "            start_x, end_x, start_y_, end_y_ = int(start_x), int(end_x), int(start_y_), int(end_y_)\n",
    "            face_image = resized_image[start_y_:end_y_, start_x:end_x]\n",
    "            new_dim_ = (146, 225) #hard coded - -will want to change if I update the _face_ratio\n",
    "            new_face = cv.resize(face_image, new_dim_, interpolation = cv.INTER_AREA)\n",
    "            faces.append(new_face)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video = 'xmkwsnuzyq.mp4'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
