{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "import tensorflow.compat.v1 as tf1\n",
    "import tensorflow_gan as tgan\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_gan as tfgan\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2 as cv\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "face_detector = MTCNN()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bucket = '/Users/jeremiahherberg/Downloads/celeba-dataset/img_align_celeba/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def input_function(mode, params):\n",
    "    batch_size = params['batch_size']\n",
    "    #confirm this will not break TPUEstimator -- if it does, will need to switch to 'noise_dims'\n",
    "    resized_height, resized_width = params['image_dims'] #s/b (225, 146)\n",
    "    #height_dim * width_dim * 3 (RGB_dim)\n",
    "    noise_dims = params['noise_dims'] #this can be an arbitrary number\n",
    "    #determine if test or train split is being used\n",
    "    split = 'train' if mode == tf.estimator.ModeKeys.TRAIN else 'test'\n",
    "    shuffle = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    just_noise = (mode ==tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    #ds to generate images\n",
    "    noise_dataset = (tf.data.Dataset.from_tensors(0)\n",
    "                    .map(lambda _ : tf.random.normal([batch_size, noise_dims]))\n",
    "                    .repeat(1 if just_noise else None))\n",
    "    \n",
    "\n",
    "    if just_noise:\n",
    "        return noise_dataset\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "    def find_face(img):\n",
    "        #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "        image_tensor = tf.expand_dims(img, 0)\n",
    "        #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "        image_tensor = tf.gather(image_tensor, 0)\n",
    "        #convert to array so face detector can read image\n",
    "        image_array = np.array(image_tensor)        \n",
    "        try:\n",
    "            '''If the face detector cannot detect a face, the first line in the try statement\n",
    "            will produce an IndexError. If this happens, pass the entire resized image into our model.\n",
    "            Given the small number of pictures in the DS this will apply to, the affect on the model\n",
    "            should be small, and a try/except statement should be more efficient than checking the len\n",
    "            of the number of faces detected on every photo in the DS.'''\n",
    "            x_start, y_start, x_len, y_len = face_detector.detect_faces(image_array)[0]['box']\n",
    "            #image array will only cover the detected face\n",
    "            face_array = image_array[y_start:(y_start + y_len), x_start:(x_start + x_len)]\n",
    "        except IndexError:\n",
    "            face_array = image_array\n",
    "        #resize array to match input of model\n",
    "        face_resized = tf.image.resize_with_pad(face_array,\n",
    "                                               target_height=resized_height, \n",
    "                                               target_width=resized_width)\n",
    "        #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "        face_resized = (tf.cast(face_resized, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "        return face_resized\n",
    "    \n",
    "\n",
    "    def find_face_dot_map_compatible(img):\n",
    "        image = img['image'] #filter\n",
    "        [image,] = tf.py_function(find_face, [image], [tf.float32])\n",
    "        return image\n",
    "    \n",
    "\n",
    "\n",
    "    image_dataset = (tfds.load('celeb_a',\n",
    "                              split=split,\n",
    "                              data_dir=ds_bucket,\n",
    "                              download=False, #tf record files should already be in the ds_bucket directory\n",
    "                              shuffle_files=True)\n",
    "                     .map(find_face_dot_map_compatible)\n",
    "                    .cache()\n",
    "                    .repeat())\n",
    "    \n",
    "    \n",
    "    if shuffle:\n",
    "        image_dataset = image_dataset.shuffle(buffer_size=205000, \n",
    "                                              reshuffle_each_iteration=True)\n",
    "        \n",
    "    image_dataset = (image_dataset.batch(batch_size,\n",
    "                                        drop_remainder=True)\n",
    "                                        .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return tf.data.Dataset.zip((noise_dataset, image_dataset))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model(input_shape=[192, 128, 3]):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(32, (5, 5), padding='same',\n",
    "                                     input_shape=input_shape)) #changed from 225*146\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "#     model.add(layers.LeakyReLU()) #- examples of GANs I have found use LeakyReLU after each COnv2D layer\n",
    "#     model.add(layers.Dropout(0.0)) #look into and consider adding dropout\n",
    "\n",
    "    model.add(layers.Conv2D(64, (5, 5), padding='same'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5, 5), padding='same'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (5, 5), padding='same'))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (5, 5), padding='same'))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    \n",
    "    model.add(layers.Conv2D(512, (5, 5), padding='same'))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "discriminator_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model(input_shape=(1028,)): #178 * 218\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(3078, use_bias=False, input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((3, 2, 256)))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', use_bias=False,\n",
    "                                    activation='tanh'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same'))\n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "generator_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
