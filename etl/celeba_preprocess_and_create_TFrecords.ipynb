{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "from google.cloud import storage\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import math\n",
    "import cv2 as cv\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "face_detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file( #file location of GCS private key\n",
    "        'xx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment below comment if working outside of colab\n",
    "client = storage.Client(project='deepfake-research')#, credentials=credentials)\n",
    "#uncomment below for testing\n",
    "objects = client.list_blobs('celeba-jh', prefix='img_align_celeba/img_align_celeba')#,max_results=100)\n",
    "image_list = []\n",
    "for object_ in objects:\n",
    "    path = str(object_).split(', ')[1]\n",
    "    image_list.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 100, \n",
    "         'image_dims': (192, 128),\n",
    "         'noise_dims': 100,\n",
    "         'ds_size': 162770,\n",
    "         'start_epoch': 1,\n",
    "         'end_epoch': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_tfExample(image):\n",
    "    #passes in an image and returns a tf.Example with the image byte string being the only feature\n",
    "    features = {\n",
    "        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image]))\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, params=params):\n",
    "  \n",
    "    resized_height, resized_width = params['image_dims'] #s/b (192, 128)\n",
    "    try:\n",
    "        '''If the face detector cannot detect a face, the first line in the try statement\n",
    "        will produce an IndexError. If this happens, pass the entire resized image into our model.\n",
    "        Given the small number of pictures in the DS this will apply to, the affect on the model\n",
    "        should be small, and a try/except statement should be more efficient than checking the len\n",
    "        of the number of faces detected on every photo in the DS.'''\n",
    "        x_start, y_start, x_len, y_len = face_detector.detect_faces(image)[0]['box']\n",
    "        #the face detector will sometimes return a negative number for the x/y starting points\n",
    "        #if a negative number is returned for a starting point, do not crop from the left/bottom\n",
    "        x_start, y_start = max(x_start, 0), max(y_start, 0)\n",
    "        #image array will only cover the detected face\n",
    "        face_array = image[y_start:(y_start + y_len), x_start:(x_start + x_len)]\n",
    "    except IndexError:\n",
    "        face_array = image\n",
    "    #resize array to match input of model\n",
    "    face_resized = tf.image.resize_with_pad(face_array,\n",
    "                                           target_height=resized_height, \n",
    "                                           target_width=resized_width)\n",
    "    #convert the dtype to tf.uint8\n",
    "    face_resized = (tf.cast(face_resized, tf.uint8)) #PIL will not accept -1 to 1\n",
    "    #convert to array\n",
    "    face_resized = np.array(face_resized)\n",
    "\n",
    "    return face_resized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_upload_tfrecord_file(start_index,\n",
    "                                    end_index,\n",
    "                                    TFRecord_object_name,\n",
    "                                    file_list=image_list,\n",
    "                                    TFRecord_bucket_name='celeba-ds-jh', #find bucket name for TFRecord files\n",
    "                                    tmp_TFRecord_file='tmp.tfrecord',\n",
    "                                    img_bucket_name='celeba-jh',\n",
    "                                    tmp_image_file='image.jpg',\n",
    "                                   ):\n",
    "    img_bucket = client.get_bucket(img_bucket_name)\n",
    "    with tf.io.TFRecordWriter(tmp_TFRecord_file) as writer:\n",
    "        for file in file_list[start_index: end_index]: \n",
    "            original_image_string = img_bucket.get_blob(file).download_as_string()\n",
    "            original_image_bytes = io.BytesIO(original_image_string)\n",
    "            original_image = Image.open(original_image_bytes)\n",
    "            original_image_array = np.array(original_image)\n",
    "            preprocessed_image = preprocess_image(original_image_array) #preprocessing step\n",
    "            preprocessed_image_ = Image.fromarray(preprocessed_image)\n",
    "            preprocessed_image_.save(tmp_image_file)\n",
    "            preprocessed_image_string = open(tmp_image_file, 'rb').read()\n",
    "            tf_example = convert_image_to_tfExample(preprocessed_image_string)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "        # preprocessed_image_string.close()\n",
    "    #upload tmp_TFRecord_file to TFRecord_bucket_name\n",
    "    TFRecord_bucket = client.get_bucket(TFRecord_bucket_name)\n",
    "    TFRecord_object = TFRecord_bucket.blob(TFRecord_object_name) #new object name\n",
    "    TFRecord_object.upload_from_filename(tmp_TFRecord_file) #old file name\n",
    "    os.remove(tmp_image_file)\n",
    "    os.remove(tmp_TFRecord_file)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_TFRecords(file_list=image_list,\n",
    "                   num_TFRecord_files=20\n",
    "                   ):\n",
    "    number_of_images = len(file_list)\n",
    "    images_per_TFRecord_file = math.ceil(number_of_images / num_TFRecord_files)\n",
    "    images_last_TFRecord_file = number_of_images % images_per_TFRecord_file\n",
    "    start_index = 0\n",
    "    TFR_counter = 1\n",
    "    for TFRecord_file in range(num_TFRecord_files):\n",
    "        if TFRecord_file == num_TFRecord_files:\n",
    "            end_index = start_index + images_last_TFRecord_file\n",
    "        else:\n",
    "            end_index = start_index + images_per_TFRecord_file\n",
    "        TFRecord_object_name = 'celeba_all_preprocessed.tfrecord_{}_of{}'.format(TFR_counter, num_TFRecord_files)\n",
    "        create_and_upload_tfrecord_file(start_index, end_index, TFRecord_object_name)\n",
    "        TFR_counter +=1\n",
    "        start_index = end_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_TFRecords()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
