{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gan mtcnn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import tensorflow_datasets as tfds\n",
    "# import tensorflow_gan as tfgan\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2 as cv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython import display\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver() #(tpu='grpc://' + ['COLAB_TPU_os.environADDR'])\n",
    "    print('Running on TPU ', resolver.master())\n",
    "except ValueError:\n",
    "    resolver = None\n",
    "\n",
    "if resolver:\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    credentials=None\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file( #file location of GCS private key\n",
    "        'xx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client(project='deepfake-research', credentials=credentials)\n",
    "objects = client.list_blobs('celeba-ds-jh', prefix='celeba_all_preprocessed')\n",
    "tfrecords = []\n",
    "for object_ in objects:\n",
    "    path = str(object_).split(', ')[1]\n",
    "    gs_path = os.path.join('gs://celeba-ds-jh', path)\n",
    "    tfrecords.append(gs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 128, \n",
    "         'image_dims': (192, 128),\n",
    "         'noise_dims': 100,\n",
    "         'ds_size': 202599,\n",
    "         'start_epoch': 1, #1, #40, #90,  \n",
    "         'end_epoch': 50,\n",
    "         'model_number': 8} #39, #89, #150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def input_function(params, mode=None):\n",
    "    batch_size = params['batch_size']\n",
    "    resized_height, resized_width = params['image_dims'] #s/b (192, 128)\n",
    "        \n",
    "#todo -- improve documentation \n",
    "    \n",
    "    \n",
    "    def preprocess_image(img):\n",
    "        #decode TFexample record\n",
    "        features_dictionary = {\n",
    "            'image': tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "        features = tf.io.parse_single_example(img, features_dictionary)\n",
    "        decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "\n",
    "        #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "        image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "        #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "        image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "        #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "        image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "        #randomly mirror images\n",
    "        image_tensor = tf.image.random_flip_left_right(image_tensor)\n",
    "\n",
    "        return image_tensor\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    image_dataset = (tf.data.TFRecordDataset(filenames = [tfrecords]).\n",
    "                     cache().\n",
    "                     map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "                     repeat())\n",
    "        \n",
    "    image_dataset = (image_dataset.batch(batch_size,\n",
    "                                        drop_remainder=True,)\n",
    "                                        .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "\n",
    "    return image_dataset\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_input_function(params):\n",
    "    batch_size = params['batch_size']\n",
    "    noise_dims = params['noise_dims'] #this can be an arbitrary number\n",
    "    #ds to generate images\n",
    "\n",
    "    noise_dataset = tf.random.normal([batch_size, noise_dims])\n",
    "    return noise_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_set_of_layers(model_, filters_, kernal, strides_, dropout=0):\n",
    "    '''\n",
    "    function to add the following layers to a discriminator model:\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, LeadyReLU, Dropout\n",
    "\n",
    "    args:\n",
    "      model_ : tf.keras.Sequential model (discriminator model)\n",
    "      filters_: int, number of filters in Conv2D layer\n",
    "      kernal: int, kernal size in Conv2D layer\n",
    "      strides_: int, stride size in MaxPooling2D layer\n",
    "      dropout: float, dropout percentage in Dropout layer, default is 0.0\n",
    "        must be less than 1.0\n",
    "\n",
    "    returns:\n",
    "      model_: tf.keras.Sequential model that is the same as the model_ input plus above \n",
    "        layers added\n",
    "    '''\n",
    "    model_.add(layers.Conv2D(filters_, (kernal, kernal), padding='same'))\n",
    "    model_.add(layers.MaxPooling2D(strides_, strides_))\n",
    "    model_.add(layers.BatchNormalization())\n",
    "    model_.add(layers.LeakyReLU())\n",
    "    # model_.add(layers.Dropout(dropout))\n",
    "\n",
    "    return model_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model(input_shape=[192, 128, 3]):\n",
    "    \n",
    "    #consider creating a singel model that takes two inputs provides two outputs\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(32, (5, 5), padding='same',\n",
    "                                     input_shape=input_shape)) #changed from 225*146\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.LeakyReLU()) #- examples of GANs I have found use LeakyReLU after each COnv2D layer\n",
    "    model.add(layers.Dropout(0.35)) \n",
    "    # model.add(layers.Dense(512)) #can add dense layers if desired\n",
    "\n",
    "\n",
    "\n",
    "    disc_set_of_layers(model, 64, 5, 2, 0.35)\n",
    "    \n",
    "\n",
    "    disc_set_of_layers(model, 128, 5, 2, 0.35)\n",
    "\n",
    "    disc_set_of_layers(model, 256, 5, 2, 0.35)\n",
    "\n",
    "    # disc_set_of_layers(model, 256, 5, 2, 0.35)\n",
    "\n",
    "    # disc_set_of_layers(model, 512, 5, 2, 0.35)\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512))\n",
    "\n",
    "    model.add(layers.Dense(2, activation='sigmoid')) \n",
    "\n",
    "    return model\n",
    "# discriminator_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_set_of_layers(x, filters, kernal, stride, bias, activ=None):\n",
    "    '''\n",
    "    function to add set of layers to generator model\n",
    "    the following layers will be added to model:\n",
    "        Conv2DTranspose\n",
    "        BatchNormalization\n",
    "        LeakyRelu\n",
    "    \n",
    "    inputs:\n",
    "        x: input tensor\n",
    "        filters (int) number of filters in Conv2DTranspose layer\n",
    "        kernal (int) kernal size (kernal, kernal) of Conv2DTranspose layer\n",
    "        stride (int) stride size (strides, strides) of Conv2DTranspose layer\n",
    "        bias (bool) value to be passed into use_bias arg in Conv2DTranspose layer\n",
    "        activ (srr) activation function of Conv2DTranspose layer\n",
    "    \n",
    "    returns:\n",
    "        x: above referenced layers added to x input\n",
    "    '''\n",
    "    x = layers.Conv2DTranspose(filters,\n",
    "                              (kernal, kernal),\n",
    "                              strides=(stride, stride),\n",
    "                              padding='same',\n",
    "                              use_bias=bias,\n",
    "                              activation=activ)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24576)             2457600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 24576)             98304     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 24576)             0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 6, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 6, 4, 1024)        26214400  \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 6, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 6, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 12, 8, 512)        13107712  \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 12, 8, 512)        2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 12, 8, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 24, 16, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 24, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 24, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 48, 32, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 48, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 48, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 96, 64, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 96, 64, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 96, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 192, 128, 3)       38403     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 192, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 192, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 61,591,055\n",
      "Trainable params: 61,535,753\n",
      "Non-trainable params: 55,302\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generator_model(params=params): #178 * 218\n",
    "    input_shape = params['noise_dims']\n",
    "#     input_shape = 50\n",
    "    input_shape = (input_shape,)\n",
    "    \n",
    "    input_tensor = layers.Input(shape=input_shape)\n",
    "    dense_layer = layers.Dense(24576, use_bias=False)(input_tensor)\n",
    "    x = layers.BatchNormalization()(dense_layer)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    #reshape \n",
    "    x = layers.Reshape((6, 4, 1024))(x)\n",
    "    \n",
    "\n",
    "    x = gen_set_of_layers(x, 1024, 5, 1, False, None) #was 1024, 5, 2\n",
    "\n",
    "    for _ in range(4):\n",
    "        num_filters = 512\n",
    "        x = gen_set_of_layers(x, num_filters, 5, 2, True, None)\n",
    "        num_filters /= 2\n",
    "    \n",
    "#     x = gen_set_of_layers(x, 512, 5, 2, True, None)\n",
    "    \n",
    "#     x = gen_set_of_layers(x, 256, 5, 2, True, None)\n",
    "\n",
    "\n",
    "#     x = gen_set_of_layers(x, 128, 5, 2, True, None)\n",
    "\n",
    "\n",
    "#     x = gen_set_of_layers(x, 64, 5, 2, True, None)\n",
    "    \n",
    "    #number of filters on last layer must be equal to 3 (one for each of R, G, B)\n",
    "    x = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    output = layers.Activation('tanh')(x)\n",
    "\n",
    "    assert(output.shape[1:] == ( *params['image_dims'], 3))\n",
    "    \n",
    "    model = keras.Model(inputs=input_tensor, outputs=output, name='generator')\n",
    "\n",
    "    return model\n",
    "generator_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(None, *params['image_dims'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real_output, fake_output):\n",
    "    '''\n",
    "    takes output from a discriminator GAN model for a batch of real and fake images\n",
    "    and returns the loss for the discriminator and generator in a GAN model\n",
    "    \n",
    "    args:\n",
    "        real_output: output from a batch of real images passed through a discriminator, a tensor\n",
    "        shapped (batch_size, 1)\n",
    "        \n",
    "        fake_output: output from a batch of fake images generated by a generator GAN model, \n",
    "        passed into a discriminator GAN model, a tensor shapped (batch_size, 1)\n",
    "        \n",
    "    returns:\n",
    "        generator_loss: the generator loss for the training batch\n",
    "        \n",
    "        discriminator_loss: the discriminator loss for the training batch\n",
    "    '''\n",
    "\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)\n",
    "    generator_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    #add some noise to target values\n",
    "    extra_noise = tf.random.uniform((1,), 0, 0.1)\n",
    "    discriminator_loss_fake = cross_entropy(tf.zeros_like(fake_output) + extra_noise, fake_output)\n",
    "    discriminator_loss_real = cross_entropy(tf.ones_like(real_output) - extra_noise, real_output)\n",
    "    discriminator_loss = discriminator_loss_fake + discriminator_loss_real\n",
    "    \n",
    "    #keep track of loss values\n",
    "    gen_loss.update_state(generator_loss)\n",
    "    disc_loss.update_state(discriminator_loss)\n",
    "    \n",
    "    #keep track of accuracy\n",
    "    acc_fake.update_state(tf.zeros_like(fake_output), fake_output)\n",
    "    acc_real.update_state(tf.ones_like(real_output), real_output) #these are backwards #fixed\n",
    "  \n",
    "    return generator_loss, discriminator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_bucket = client.bucket('jh-gan-testing')\n",
    "    model_name_generator =  'na' # 'gen6_epoch230.h5'  #'gen_5.h5' \n",
    "    model_name_discriminator =  'na'  # 'disc6_epoch230.h5' #'disc_5.h5' \n",
    "    model_blob_g = model_bucket.blob(model_name_generator)\n",
    "    model_blob_g.download_to_filename(model_name_generator)\n",
    "    model_blob_d = model_bucket.blob(model_name_discriminator)\n",
    "    model_blob_d.download_to_filename(model_name_discriminator)\n",
    "    # create the models and optimizers in the strategy.scope\n",
    "    with strategy.scope():\n",
    "        generator = tf.keras.models.load_model(model_name_generator)\n",
    "        discriminator = tf.keras.models.load_model(model_name_discriminator)\n",
    "    print('loaded partially trained models')\n",
    "except:\n",
    "    with strategy.scope():\n",
    "        generator = generator_model()\n",
    "        discriminator = discriminator_model()\n",
    "    print('created new models')\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(1e-4) \n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(5e-5) #SGD #Adam\n",
    "    #metrics\n",
    "    #loss\n",
    "    gen_loss = tf.keras.metrics.Mean('gen_loss', dtype=tf.float32)\n",
    "    disc_loss = tf.keras.metrics.Mean('disc_loss', dtype=tf.float32)\n",
    "\n",
    "    #discriminator accuracy on real and fake images\n",
    "    acc_real = tf.keras.metrics.BinaryAccuracy('acc_real', threshold=0.5)\n",
    "    acc_fake = tf.keras.metrics.BinaryAccuracy('acc_fake', threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(params, real_images_, train_disc=False, train_gen=False):\n",
    "    generator_input_ = generator_input_function(params)\n",
    "\n",
    "#make the below a function\n",
    "#inputs real_images, generator_input\n",
    "    def disc_train_step(generator_input, real_images):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            fake_images = generator(generator_input, training=False)\n",
    "\n",
    "\n",
    "            real_output = discriminator(real_images, training=True)\n",
    "            fake_output = discriminator(fake_images, training=True)\n",
    "\n",
    "            generator_loss, discriminator_loss = loss_function(real_output, fake_output)\n",
    "\n",
    "        #update disc gradients\n",
    "        discriminator_gradients = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "\n",
    "    def gen_train_step(generator_input, real_images):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            fake_images = generator(generator_input, training=True)\n",
    "\n",
    "\n",
    "            real_output = discriminator(real_images, training=False)\n",
    "            fake_output = discriminator(fake_images, training=False)\n",
    "\n",
    "            generator_loss, discriminator_loss = loss_function(real_output, fake_output)\n",
    "\n",
    "\n",
    "        #update generator gradients\n",
    "        generator_gradients = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "        \n",
    "\n",
    "\n",
    "    #will train the disc or generator based on args passed into fn \n",
    "    if train_disc:\n",
    "        strategy.run(disc_train_step, args=(generator_input_, real_images_))\n",
    "    if train_gen:\n",
    "        strategy.run(gen_train_step, args=(generator_input_, real_images_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_generated_pic(gen_output_tensor, return_=False):\n",
    "    '''\n",
    "    Function to convert tensor from a range of -1 to 1 -> 0 to 1 and display the resulting image\n",
    "    Will display the converted tensor as an image and can return a tensor that is converted as per above\n",
    "    '''\n",
    "    generated_image = (gen_output_tensor + 1) / 2\n",
    "    # generated_image = gen_output_tensor\n",
    "    plt.imshow(generated_image)\n",
    "    plt.show()\n",
    "    if return_:\n",
    "        return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = params['ds_size'] #celeba DS is 162,770 images for training\n",
    "start_epoch = params['start_epoch']\n",
    "end_epoch = params['end_epoch']\n",
    "batch_size = params['batch_size']\n",
    "params_ = {}\n",
    "params_['noise_dims'] = params['noise_dims']\n",
    "\n",
    "params_['batch_size'] = 1\n",
    "steps_per_epoch = int(tf.math.ceil(ds_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = input_function(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training code\n",
    "step_counter = 0\n",
    "model_num = params['model_number']\n",
    "loss_gen = []\n",
    "loss_disc = []\n",
    "real_accuracy = []\n",
    "fake_accuracy = []\n",
    "step = []\n",
    "# epochs = end_epoch - start_epoch \n",
    "model_bucket = client.bucket('jh-gan-testing')\n",
    "for epoch in range(start_epoch, end_epoch + 1):\n",
    "    if epoch % 10 == 0:\n",
    "        gen_model_name = 'gen{}_epoch{}.h5'.format(model_num, epoch)\n",
    "        disc_model_name = 'disc{}_epoch{}.h5'.format(model_num, epoch)\n",
    "        generator.save(gen_model_name)\n",
    "        discriminator.save(disc_model_name)\n",
    "        #upload generator model\n",
    "        blob = model_bucket.blob(gen_model_name)\n",
    "        blob.upload_from_filename(gen_model_name)\n",
    "\n",
    "        #upload disc model\n",
    "        blob = model_bucket.blob(disc_model_name)\n",
    "        blob.upload_from_filename(disc_model_name)\n",
    "\n",
    "\n",
    "    tf.random.set_seed(epoch)\n",
    "    if epoch %2 == 1:\n",
    "        #alternate training discriminator/generator every other epoch\n",
    "        disc_train, gen_train = True, False\n",
    "    else:\n",
    "        disc_train, gen_train = False, True\n",
    "    tme_start = time.time()\n",
    "    for image_batch in real_images:\n",
    "      # start = time.time()\n",
    "        training_step(params, image_batch, disc_train, gen_train)\n",
    "        end = time.time()\n",
    "        tme= end - tme_start\n",
    "        step_counter +=1\n",
    "        if step_counter %395 == 394:\n",
    "            step.append((epoch - 1) * steps_per_epoch + step_counter)\n",
    "            loss_gen.append(gen_loss.result().numpy())\n",
    "            loss_disc.append(disc_loss.result().numpy())\n",
    "            real_accuracy.append(acc_real.result().numpy())\n",
    "            fake_accuracy.append(acc_fake.result().numpy())\n",
    "\n",
    "            #reset states of metrics\n",
    "            gen_loss.reset_states()\n",
    "            disc_loss.reset_states()\n",
    "            acc_real.reset_states()\n",
    "            acc_fake.reset_states()\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "            print('step {}, epoch {}'.format(step_counter, epoch))\n",
    "            print('total time: {} seconds // {} per step'. format ((end - tme_start), \n",
    "                                                                   ((end- tme_start) / step_counter)))\n",
    "            gen_input = generator_input_function(params_)\n",
    "            gen_output = generator(gen_input)\n",
    "            _ = display_generated_pic(gen_output[0])\n",
    "            print(params)\n",
    "                    #step  #loss\n",
    "            plt.plot(step, loss_gen, label='gen')\n",
    "            plt.plot(step, loss_disc, label='disc')\n",
    "            plt.ylabel('loss')\n",
    "            plt.xlabel('step')\n",
    "            plt.legend()#('upper left')\n",
    "            plt.show()\n",
    "\n",
    "            #todo - make into a function \n",
    "            plt.plot(step, real_accuracy, label='real')\n",
    "            plt.plot(step, fake_accuracy, label='fake')\n",
    "            plt.ylabel('accuracy')\n",
    "            plt.xlabel('step')\n",
    "            plt.legend()#('upper left')\n",
    "            plt.show()\n",
    "\n",
    "        if step_counter > steps_per_epoch:\n",
    "            step_counter = 0\n",
    "            #reset states of metrics\n",
    "            gen_loss.reset_states()\n",
    "            disc_loss.reset_states()\n",
    "            acc_real.reset_states()\n",
    "            acc_fake.reset_states()\n",
    "            break #end epoch\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model_path = 'gen_8.h5'\n",
    "disc_model_path = 'disc_8.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save(gen_model_path)\n",
    "discriminator.save(disc_model_path)\n",
    "blob = model_bucket.blob(gen_model_path)\n",
    "blob.upload_from_filename(gen_model_path)\n",
    "blob = model_bucket.blob(disc_model_path)\n",
    "blob.upload_from_filename(disc_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = generator_input_function(params)\n",
    "gen_output = generator(gen_input)\n",
    "_ = display_generated_pic(gen_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.arange(1, 50):\n",
    "  _ = display_generated_pic(gen_output[x])\n",
    "  time.sleep(0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dictionary = {\n",
    "    'step': step_counter,\n",
    "    'gen_loss': loss_gen,\n",
    "    'disc_loss': loss_disc,\n",
    "    'real_acc': real_accuracy, \n",
    "    'fake_acc': fake_accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.DataFrame(train_data_dictionary)\n",
    "# train_data_df.to_csv('train_data.csv')\n",
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.activations.sigmoid(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
